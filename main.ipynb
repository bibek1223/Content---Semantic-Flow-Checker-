from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import ipywidgets as widgets
from IPython.display import display, clear_output
import re

model = SentenceTransformer('all-MiniLM-L6-v2')

THRESHOLDS = {
    'sentence': {'low': 0.60, 'ideal': (0.70, 0.90), 'high': 0.95},
    'paragraph': {'low': 0.55, 'ideal': (0.65, 0.85), 'high': 0.90},
    'section': {'low': 0.45, 'ideal': (0.50, 0.80), 'high': 0.85}
}

def check_similarity(text_list, level):
    results = []
    embeddings = model.encode(text_list)
    pairs = list(zip(text_list, text_list[1:], embeddings, embeddings[1:]))
    for idx, (a, b, vec_a, vec_b) in enumerate(pairs):
        score = cosine_similarity([vec_a], [vec_b])[0][0]
        threshold = THRESHOLDS[level]
        if score > threshold['high']:
            comment = "Redundant. Rephrase or remove repetition."
        elif score < threshold['low']:
            comment = "Too disconnected. Add bridging sentence or transition."
        elif threshold['ideal'][0] <= score <= threshold['ideal'][1]:
            comment = "Good semantic flow."
        else:
            comment = "Slight deviation. Consider reworking the transition."
        results.append((a, b, score, comment))
    return results

def split_into_paragraphs(text):
    return [p.strip() for p in text.split('\n\n') if p.strip()]

def parse_headings(headings_text):
    headings = []
    for line in headings_text.splitlines():
        line = line.strip()
        m = re.match(r'<H([1-3])>\s*(.*)', line, re.I)
        if m:
            level = int(m.group(1))
            title = m.group(2).strip()
            headings.append({'level': level, 'title': title})
    return headings

def assign_content_to_headings_multiple_levels(headings, content, levels=[1,2]):
    paragraphs = split_into_paragraphs(content)
    assigned_all = []

    for level in levels:
        top_headings = [h for h in headings if h['level'] == level]
        n = len(paragraphs)
        m = len(top_headings)
        if m == 0:
            continue
        approx_chunk_size = max(1, n // m)

        idx = 0
        for i, heading in enumerate(top_headings):
            if i < m - 1:
                chunk = paragraphs[idx: idx + approx_chunk_size]
                idx += approx_chunk_size
            else:
                chunk = paragraphs[idx:]
            assigned_all.append({'heading': heading, 'paragraphs': chunk, 'level': level})
    return assigned_all

def analyze_assigned_content_by_level(assigned):
    output_lines = []
    for level in sorted(set(item['level'] for item in assigned)):
        items = [item for item in assigned if item['level'] == level]
        titles = [item['heading']['title'] for item in items]
        if len(titles) > 1:
            sims = check_similarity(titles, 'section')
            output_lines.append(f"=== Section-to-Section Flow (H{level}) ===")
            for i, (a, b, score, comment) in enumerate(sims):
                output_lines.append(f"Between '{a}' and '{b}': {comment} (score: {score:.3f})")
            output_lines.append("")
        output_lines.append(f"=== Paragraph-to-Paragraph Flow (H{level}) ===")
        for item in items:
            heading = item['heading']
            paras = item['paragraphs']
            output_lines.append(f"Under {heading['title']}:")
            if len(paras) < 2:
                output_lines.append("  Not enough paragraphs for analysis.")
                continue
            sims = check_similarity(paras, 'paragraph')
            for i, (a, b, score, comment) in enumerate(sims):
                output_lines.append(f"  Paragraph {i+1} to {i+2}: {comment} (score: {score:.3f})")
            output_lines.append("")
    return '\n'.join(output_lines)

def define_context(paragraphs):
    """
    Define the context of each paragraph by comparing it to others.
    If a paragraph has a low similarity with the rest, it's considered 'out of context.'
    """
    embeddings = model.encode(paragraphs)
    similarities = cosine_similarity(embeddings)

    context = []
    for i, sim_row in enumerate(similarities):
        avg_similarity = sum(sim_row) / len(sim_row)
        if avg_similarity < 0.5:  # Threshold for out-of-context
            context.append((paragraphs[i], "Out of context. Consider adding more details."))
        else:
            context.append((paragraphs[i], "Well-aligned with main context."))
    
    return context

def generate_improvement_suggestions(paragraphs, context):
    """
    Suggest improvements for disconnected paragraphs.
    - If a paragraph is out of context, suggest bridging sentences.
    - If the paragraph lacks content, suggest expanding it.
    """
    suggestions = []
    for i, (para, stat) in enumerate(context):
        if stat == "Out of context. Consider adding more details.":
            suggestions.append(f"Paragraph {i+1} is out of context. Suggest adding a bridging sentence or more background information.")
        elif stat == "Well-aligned with main context.":
            suggestions.append(f"Paragraph {i+1} is aligned with the main context.")
    
    return suggestions

# Widgets
headings_input = widgets.Textarea(
    value='''<H1> What is an IT Service Provider? Types, Importance, and Requirements
<H2> What Service Does IT Service Provider Offer?
<H2> What Does the IT Service Provider Do?
<H2> Types of IT Service Provider
<H3> 1. Consultation and Strategy
<H3> 2. Internet Service Provider (ISP)
<H3> 3. Cloud Service Provider
<H3> 4. Network and Cloud Security Service Provider
<H3> 5. Digital Adoption Service Provider
<H3> 6. SaaS Service Provider
<H3> 7. Hosting Service Provider
<H2> Why Do Companies Require IT Service Providers?
<H2> How to Choose the Right IT Service Provider?''',
    placeholder='Paste heading tags and titles here, one per line',
    description='Headings:',
    layout=widgets.Layout(width='100%', height='200px')
)

content_input = widgets.Textarea(
    value='Paste your full content text here without headings.',
    placeholder='Paste full content text here...',
    description='Content:',
    layout=widgets.Layout(width='100%', height='300px')
)

analyze_button = widgets.Button(description="Analyze Semantic Flow")

output_area = widgets.Output(layout={'border': '1px solid black'})

def on_analyze_clicked(b):
    with output_area:
        clear_output()
        headings_text = headings_input.value.strip()
        content_text = content_input.value.strip()
        if not headings_text or not content_text:
            print("Please enter both headings and content.")
            return
        headings = parse_headings(headings_text)
        assigned_content = assign_content_to_headings_multiple_levels(headings, content_text, levels=[1,2])
        result = analyze_assigned_content_by_level(assigned_content)
        
        # Context Definition and Improvement Suggestions
        paragraphs = split_into_paragraphs(content_text)
        context = define_context(paragraphs)
        suggestions = generate_improvement_suggestions(paragraphs, context)
        
        # Output results
        print(result)
        print("\nImprovement Suggestions:\n")
        for suggestion in suggestions:
            print(suggestion)

analyze_button.on_click(on_analyze_clicked)

display(headings_input, content_input, analyze_button, output_area)
